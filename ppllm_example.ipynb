{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/PaulLerner/ppllm/blob/main/ppllm_example.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aydvod5vup_2"
   },
   "outputs": [],
   "source": [
    "%pip install ppllm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load your model as usual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "TS7fltiQvjcy"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 630,
     "referenced_widgets": [
      "998ba32940fe46d7a6e66e46f4e06df8",
      "1d6ae075f07b4f29aff61d0a150f5092",
      "238dedbbf4274272ad4f276130ebe547",
      "c9841f0033d3441db6c83d92c60df57f",
      "c9dc9f335bff4df29630986a68189c98",
      "f2f127486158484da1ff26b39e3c9360",
      "1ec78c5346b64d398be4c1de30628a1f",
      "2f3fcbcab80a4efa9a23249d454d53f9",
      "71721c9ba9e144cf87f0e21cd1c7c549",
      "8c8cd614b6f34967b4ddd0ccc6a6f04e",
      "39f686103d7f49d6a279ee682ba485eb",
      "de3f1028148a482f8d6769f517a8b96e",
      "cbcaa8a8480b4eddb790efffbc150c4f",
      "1ec5ccb35d3c4bf5af9e4ac2efe947a8",
      "323f35cc590640aca01fbabd44a7165a",
      "fe7ec34135f94bd8aaf96801fd9e4a6d",
      "ea360ef17211404a9f946605415d0d33",
      "4233bf3731f640f8b39ee470618de73b",
      "a363e1c2f2d7426b9a8a31ed690c6f20",
      "cb282d4fb39241819f1572a1e03d6bb7",
      "81960425a064453baae59d83754fb11b",
      "94f254ec980343f297e44fd820b59b29",
      "a6753bb7ffcc46ac9650fb79f12ff847",
      "57d391e537864f85bbb7a2f7494dd58d",
      "db1b210ab8554a8ca8bf93265d99d1d2",
      "1f94b60443b84054ba14aba548411310",
      "f8d8afde4cb345f19fcd8d3213178307",
      "0139af0df87c4683a7755327e74a4685",
      "7581d04046dd46aa9b4fcc0e2e82f1ae",
      "f8043786686343fb944be86191e97d35",
      "feb9f27a950643f38e9d8f34f6620216",
      "572b286861264f2eac98470d092215ac",
      "a0427d9d6e6d44cca09cf14c73c02466",
      "7c98cb3b4dd84355956c99c6062277a0",
      "6907b169babc4b9d9ed66a607abc544d",
      "583e6cac60f74dd7bfd991cd540f256c",
      "152893ffb2c4459db03cc1360c09f66e",
      "80a54cde11e148639d9876273126baf8",
      "77ffc882f5134bf39b851faf75e184bf",
      "6861b61b1c0b4fafa8b601c111530ac2",
      "bd5133d305fc47998e7f8f683a3c5a18",
      "cb57996936f24df8a34c944237fa0e94",
      "8952eee63b82494d875aa96280d25bae",
      "8d1c860ad6024d91995024b098bf63ad",
      "1fbe430cc18643cc9ebb334e15621d83",
      "cc6fba552692424b95d1abab47e9e5f2",
      "ddc3ece38c844924a70c28f4f07b76a4",
      "83424fed5fa84123a949b4891ac8c544",
      "08b41c366afe404ca4b1fbffe75f9eaa",
      "95c8919fc185400185e7cb797814dd7e",
      "17e4142682e841128b8da73d780575dd",
      "d30310877b1c430e869300391633ec25",
      "f247f8935f3847718cec9777f1fc513f",
      "dc22542479bf471bb338f630e392edfc",
      "4a4bf71a558148318ca173ac73da0434",
      "281358e25c844afa8ae802370aac73d7",
      "919ec00545de4fc5b3f9174b2f07436b",
      "5e66852e9e9a47f88dd0456865c6813f",
      "42af6fcc53c1485992806f162052effd",
      "31ec3dce468542ce9f60a45833c01566",
      "dcc6e719d5034f64b5a249463e3419c2",
      "09b5fc9c32624385b901e8920c575416",
      "7fc11ca0ffe84f3cb60d61608fdc2f39",
      "7383e91cf454494191c80ba9df1eb30e",
      "5aaa309105804596bfb64e882fdbe553",
      "de83d403d7d24df5ab11b54d91d69648",
      "67a05acbd6d6489394b0e7cafa040242",
      "2132368039d049a39528bb94d87132de",
      "2acbb369cdd84581b95701a00c7dc233",
      "c4839f72c59347d7b70632f65c9ea4ed",
      "76faf71f7fd746d4b65d0fd73101dfcc",
      "a511899cfcee4cfea74853f1575bf04d",
      "2b675376ab384a02ab4f821fe5e035cd",
      "dac1706f8bf1443db6e8c96f97957858",
      "8708008b35164ed1baac4c0b347be3e1",
      "b95f9c9d4bfc4fec85aed12d6457c4f6",
      "a54bdb9492f34736859f2adc14c98be7",
      "72ff09c13bf34eeeab8abe76dcc6c69f",
      "f7f730ed27b04a6ab937085ff600221b",
      "d8ee4fa4c97f41afaca4184c281c11d6",
      "6e3f4194b27348d0acb7c94dfdf65bc2",
      "c192cf6b5b5c467ab24468b858a27ba0",
      "7aa10c2d9d8b474fb5d5c021dc0a5730",
      "0baeac435c4b4912a1c3a7a17fc3c805",
      "f44de8cd437d44f2b8f66e33531269bb",
      "027d3f84e20d4669acb61fac97bab9b4",
      "02083fe70be048789e4145f5287a20d0",
      "b37b2dccf2ef436eaeb67944bfc2c79d"
     ]
    },
    "id": "SRQvnqkLvqad",
    "outputId": "dd9e65a3-627c-4b60-a7ab-10ce79436725"
   },
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\"Qwen/Qwen3-0.6B-Base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "JWwhDjT3v0_m"
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen3-0.6B-Base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "xoICFA9bx74C"
   },
   "outputs": [],
   "source": [
    "model=model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute the PPL of your texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "psIvEuLbxnt-"
   },
   "outputs": [],
   "source": [
    "from ppllm.ppl import compute_ppl, compute_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\"I have a dream\", \"I'm out for dead presidents to represent me\", \"A language is a dialect with an army and navy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = compute_ppl(texts, model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ppl': 110.02603157908506,\n",
       " 'bpc': 1.5292071104049683,\n",
       " 'surprisal': 155.9791259765625}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_metrics(**{k: outputs[k] for k in [\"total_losses\", \"total_chars\", \"total_tokens\"]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use case: QA\n",
    "For MCQ tests, you might want to compute the surprisal of each possible answer to get the best one\n",
    "\n",
    "For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['What is the capital of France? Paris',\n",
       " 'What is the capital of France? Lyon',\n",
       " 'What is the capital of France? Marseille',\n",
       " 'What is the capital of France? Hogwarts']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"What is the capital of France?\"\n",
    "choices = [\n",
    "    \"Paris\",\n",
    "    \"Lyon\",\n",
    "    \"Marseille\",\n",
    "    \"Hogwarts\"\n",
    "]\n",
    "texts = [f\"{question} {choice}\" for choice in choices]\n",
    "texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = compute_ppl(texts, model, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paris is the correct answer, Lyon and Marseille are roughly as surprising, and Hogwarts is very surprising!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ppllm.ppl import sample_level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = sample_level(**{k: outputs[k] for k in [\"total_losses\", \"total_chars\", \"total_tokens\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([30.7141, 38.9278, 37.4205, 45.2356])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics[\"surprisals\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ppls': tensor([14.3131, 29.1612, 25.5911, 50.3687]),\n",
       " 'bpcs': tensor([0.8532, 1.1122, 0.9355, 1.1599]),\n",
       " 'surprisals': tensor([30.7141, 38.9278, 37.4205, 45.2356])}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
